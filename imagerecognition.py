# -*- coding: utf-8 -*-
"""ImageRecognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dP2MaSyoYMCeKhvNfEk8_RTPTEl4xHVQ
"""

import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, models
import image_dataloader
import os
import tqdm
import torch
import matplotlib.pyplot as plt
from testshuffling import *


def train(epoch, device):
    model.train()

    tr_loss = 0
    # getting the training set
    for batch in train_dataloader:
        images, labels = batch
        images = images.to(device)
        labels = labels.to(device)

        # clearing the Gradients of the model parameters
        optimizer.zero_grad()

        # prediction for training set
        output_train = model(images)

        # computing the training loss
        loss_train = lossfun(output_train, labels)
        train_losses.append(loss_train)
        # computing the updated weights of all the model parameters
        loss_train.backward()
        optimizer.step()
        tr_loss = loss_train.item()


def validation(epoch, device):
    model.eval()
    total_loss = 0

    for batch in val_dataloader:
        images, labels = batch
        images = images.to(device)
        labels = labels.to(device)

        output_val = model(images)
        loss_train = lossfun(output_val, labels)
        total_loss += loss_train
    return(total_loss)
    


if __name__ == '__main__':

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    cwd = os.getcwd()

    images_root_path = os.path.join(cwd, 'data/GroceryStoreDataset-master/dataset/')
    train_csv_path = os.path.join(cwd, 'data/GroceryStoreDataset-master/dataset/shuffledtrain.txt')
    val_csv_path = os.path.join(cwd, 'data/GroceryStoreDataset-master/dataset/val.txt')
    test_csv_path = os.path.join(cwd, 'data/GroceryStoreDataset-master/dataset/test.txt')
    img_height = 348
    img_width = 348
    batch_size = 32
    num_workers = 4
    num_classes = 43

    print("Initializing model")
    model = models.alexnet(pretrained=True)
    model.classifier[6] = nn.Linear(4096, num_classes)
    #model_name = "fifth_model.pt"
    #model = torch.load(model_name)
    model = model.to(device)

    # Let's define an optimizer
    print("Initializing optimizer")
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # Let's define a Loss function
    lossfun = nn.CrossEntropyLoss()  # Use nn.CrossEntropyLoss with softmax

    print("Initializing dataloader")
    dataloader = image_dataloader.GroceryStoreDataloader(images_root_path,
                                        train_csv_path,
                                        val_csv_path,
                                        test_csv_path,
                                        img_height,
                                        img_width,
                                        batch_size,
                                        num_workers)

    dataloader.setup()

    train_dataloader = dataloader.train_dataloader()
    val_dataloader = dataloader.val_dataloader()

    # defining the number of epochs
    n_epochs = 2
    # empty list to store training losses
    train_losses = []
    # empty list to store validation losses
    val_losses = []
    # empty list to store validation accuracy
    #val_acu = []
    # training the model

    print("Training model")

    for epoch in tqdm.trange(n_epochs):
        print(f"Training epoch {epoch}")
        train_losses.append(train(epoch, device))
        shuffling()


        train(epoch, device)
        print(f"Validation loss: {validation(epoch, device)}")
        val_losses.append(validation(epoch, device))
        #accuracy = (output.argmax(-1) == labels).float().mean()
        #val_acu.append(validation(epoch, device))

    print("Done!")

    PATH = "sixth_model.pt"
    torch.save(model, PATH)

    plt.figure(figsize=(10, 5))
    #plt.subplot(1, 2, 1)
    plt.plot(val_losses)
    plt.xlabel('batch')
    plt.ylabel('loss')
    #plt.subplot(1, 2, 2)
    #plt.plot(val_acu)
    #plt.xlabel('batch')
    #plt.ylabel('accuracy')
    #plt.plot(train_losses, label='Training loss')
    #plt.plot(val_losses, label = 'Validation loss')
    plt.show()

