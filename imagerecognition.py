# -*- coding: utf-8 -*-
"""ImageRecognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dP2MaSyoYMCeKhvNfEk8_RTPTEl4xHVQ
"""

import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, models
import image_dataloader
import os
import tqdm
import torch
import matplotlib.pyplot as plt
from testshuffling import *


def train(epoch, device):
    model.train()

    tr_loss = 0
    # getting the training set
    for batch in train_dataloader:
        images, labels = batch
        images = images.to(device)
        labels = labels.to(device)

        # clearing the Gradients of the model parameters
        optimizer.zero_grad()

        # prediction for training set
        output_train = model.forward(images)

        # computing the training loss
        loss_train = lossfun(output_train, labels)
        train_losses.append(loss_train)
        # computing the updated weights of all the model parameters
        loss_train.backward()
        optimizer.step()
        tr_loss = loss_train.item()

        del images
        del labels


def validation(epoch, device):
    model.eval()
    total_loss = 0
    with torch.no_grad():
        for batch in val_dataloader:
            images, labels = batch
            images = images.to(device)
            labels = labels.to(device)

            output_val = model.forward(images)
            loss_train = lossfun(output_val, labels)
            total_loss += float(loss_train.detach())
    return(total_loss)

    
class ModifiedAlexNet(nn.Module):
    def __init__(self, pretrained_model, num_classes):
        super(ModifiedAlexNet, self).__init__()
        self.pretrained = pretrained_model
        self.new_layers = nn.Sequential(nn.ReLU(),
                                        nn.Linear(1000, num_classes),
                                        nn.Softmax(dim=1))
    
    def forward(self, x):
        x = self.pretrained(x)
        x = self.new_layers(x)
        return x

if __name__ == '__main__':

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    cwd = os.getcwd()

    images_root_path = os.path.join(cwd, 'data/GroceryStoreDataset-master/dataset/')
    train_csv_path = os.path.join(cwd, 'data/GroceryStoreDataset-master/dataset/train.txt')
    val_csv_path = os.path.join(cwd, 'data/GroceryStoreDataset-master/dataset/val.txt')
    test_csv_path = os.path.join(cwd, 'data/GroceryStoreDataset-master/dataset/test.txt')
    img_height = 348
    img_width = 348
    batch_size = 32
    num_workers = 4
    num_classes = 43

    print("Initializing model")

    pretrained_model = models.alexnet(pretrained=True)
    model = ModifiedAlexNet(pretrained_model, num_classes)
    model = model.to(device)
    print(model)
    # Let's define an optimizer
    print("Initializing optimizer")
    optimizer = optim.Adam(model.parameters(), lr=0.00001)

    # Let's define a Loss function
    lossfun = nn.CrossEntropyLoss()  # Use nn.CrossEntropyLoss with softmax

    print("Initializing dataloader")
    dataloader = image_dataloader.GroceryStoreDataloader(images_root_path,
                                        train_csv_path,
                                        val_csv_path,
                                        test_csv_path,
                                        img_height,
                                        img_width,
                                        batch_size,
                                        num_workers)

    dataloader.setup()

    train_dataloader = dataloader.train_dataloader()
    val_dataloader = dataloader.val_dataloader()
    test_dataloader = dataloader.test_dataloader()

    # defining the number of epochs

    n_epochs = 20

    # empty list to store training losses
    train_losses = []
    # empty list to store validation losses
    val_losses = []
    # empty list to store validation accuracy
    #val_acu = []
    # training the model

    print("Training model")

    for epoch in tqdm.trange(n_epochs):
        print(f"Training epoch {epoch}")
        train_losses.append(train(epoch, device))


        train(epoch, device)
        print(f"Validation loss: {validation(epoch, device)}")
        val_losses.append(validation(epoch, device))
        #accuracy = (output.argmax(-1) == labels).float().mean()
        #val_acu.append(validation(epoch, device))


    PATH = "saved_models/seventh_model.pt"
    torch.save(model, PATH)

    test_correct = []

    with torch.no_grad():
        for batch in test_dataloader:
            images, labels = batch
            images = images.to(device)
            labels = labels.to(device)

            predictions = model.forward(images)
            correct_predictions = (torch.argmax(predictions, dim=1) == labels).type(torch.FloatTensor)
            test_correct.append(correct_predictions)

    test_correct = torch.stack(test_correct)

    print(torch.mean(test_correct))
    #plt.plot(val_losses)
    #plt.show()

    print("Done!")

    plt.figure(figsize=(10, 5))
    #plt.subplot(1, 2, 1)
    plt.plot(val_losses)
    plt.xlabel('batch')
    plt.ylabel('loss')
    #plt.subplot(1, 2, 2)
    #plt.plot(val_acu)
    #plt.xlabel('batch')
    #plt.ylabel('accuracy')
    #plt.plot(train_losses, label='Training loss')
    #plt.plot(val_losses, label = 'Validation loss')
    plt.show()


